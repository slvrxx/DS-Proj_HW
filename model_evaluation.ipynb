{
 "cells": [
     {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
             "# Model Evaluation"
         ]
     },
     {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
             "In this notebook, we will evaluate the performance of our trained models using various metrics."
         ]
     },
     {
         "cell_type": "code",
         "metadata": {},
         "source": [
             "import pandas as pd\n",
             "from sklearn.metrics import accuracy_score, classification_report\n",
             "\n",
             "# Assuming model was saved as 'trained_model.pkl' and test data as 'X_test.csv' and 'y_test.csv'\n",
             "# model = joblib.load('../Modeling/trained_model.pkl')\n",
             "# X_test = pd.read_csv('../Data Preparation/X_test.csv')\n",
             "# y_test = pd.read_csv('../Data Preparation/y_test.csv')\n",
             "\n",
             "# Predictions\n",
             "# y_pred = model.predict(X_test)\n",
             "\n",
             "# Metrics\n",
             "# accuracy = accuracy_score(y_test, y_pred)\n",
             "# report = classification_report(y_test, y_pred)\n",
             "\n",
             "# print(f'Accuracy: {accuracy:.2f}')\n",
             "# print('Classification Report:')\n",
             "# print(report)"
         ],
         "execution_count": null,
         "outputs": []
     }
 ],
 "metadata": {
     "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
     },
     "language_info": {
         "codemirror_mode": {
             "name": "ipython",
             "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.8"
     }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
